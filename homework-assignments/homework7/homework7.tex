\documentclass{article}
\usepackage{a4wide}
\usepackage{amsmath}
\usepackage{url}
\usepackage{amssymb}
\usepackage{clrscode3e}
\usepackage{tikz}
\usepackage{bm}
\usepackage{graphicx}
\graphicspath{ {./images/} }

\title{Homework 7}
\author{Joni Vrapi}
\date{12/5/2022}

\begin{document}

\maketitle

\textbf{Statement of Integrity:} I, Joni Vrapi, attempted to answer each question honestly and to the best of my abilities. I cited any, and all, help that I received in completing this assignment.

\hfill

\textbf{Problem 1a.} The variables in this problem represent decisions that must be made about the problem space, otherwise referred to as decision variables. Given that the score matrix is $M \times N$ in the reals $\mathbb{R}$, the number of variables in this problem would be $N$.

\hfill

\textbf{Problem 1b.} The objective function should be defined as a function which maximizes the sum of the similarity scores from each track/detection pair:

\begin{gather}
    maximize \sum_{j=1}^N s_{ij}
\end{gather}

\hfill

\textbf{Problem 1c.} The constraints here are that the score matrix exists, e.g. objects are found, detections can be matched only to a single track, and tracks cannot be assigned more than once. This leads to the following standard form linear program:

\begin{gather}
    
\end{gather}

\hfill

\textbf{Problem 2a.} If we let $x = (x_1, x_2, x_3)$ and $y = (y_1, y_2, y_3)$, then the expected loss for Player 1 can be calculated as $\sum{xAy^T}$ resulting in:

\begin{gather}
    x_1(y_2-y_3) + x_2(y_3-y_1) + x_3(y_1-y_2)
\end{gather}

\hfill

\textbf{Problem 2b.} Player 2 playing any strategy other than $(\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$ will allow Player 1 to adjust his strategy to play off of Player 2's strategy, resulting in an expected gain for Player 1. For example, assume Player 2 plays $(1, 0, 0)$. Player 1 would then adjust his strategy to play $(0, 1, 0)$ resulting in an expected gain of 1 (from equation 1). Likewise, it is obvious that regardless of what strategy Player 2 chooses, other than $(\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$, Player 1 will always be able to play off of it towards an expected gain.

\hfill

\textbf{Problem 2c.} Letting $x = y = (\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$ results in an expected outcome per (1) of 0. This result is indicative of both players winning the same amount of times, on average, resulting in a draw. The sticking point here, however, is that neither player has an incentive to change strategies. If one player were to choose an imbalanced strategy, the other player could alter their strategy to take advantage of it resulting in an expected gain for the other player. Therefore, we have reached a Nash equilibrium. 

\hfill

\textbf{Problem 2d.} No, it is not possible for some mixed strategy  where $y' \neq (\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$ to form a Nash equilibrium because any mixed strategy where rock, paper, or scissors are played in an imbalanced way will allow for the other player to play a strategy where the balance was reversed to accumulate more wins. For example, if Player 2 were to choose slightly more rock than paper or scissors, Player 1 could change their strategy to favor paper by the same amount, resulting in an expected gain.

\hfill

\textbf{Problem 3a.} From \cite{website:1} we choose:

\begin{codebox}
    \Procname{\proc{Facility-Location()}}
    \li with $R = U$ and $T = \emptyset$
    \li \While $R$ is not empty \Do
    \li $c = min_{u \in R, s \in T} d_{us}$
    \li select $s \in R \ T$ and set $U_s \subset R$ that minimizes: $c' = \frac{f_s + \sum{}_{u \in U_s}d_{us}}{|U_s|}$
    \li
    \li \If $c' \leq c$ \Then
    \li select the site s and set $U_s$ used to obtain $c'$ above
    \li add $s$ to $T$ and delete $U_s$ from $R$
    \li set $c_u = c'$ for all $u \in U_s$
    \li
    \li \Else
    \li select $s$ and $u$ obtaining the first minimum
    \li add $u$ to $U_s$
    \li set $c_u = c$ \End \End
\end{codebox}

\hfill

\textbf{Problem 3b.} From \cite{website:1} we consider an optimal solution which contains a subset $T^*$ of sites, and $s \in T^*$ is used to cover a set $U_s^*$ of users. The cost of using $s$ to cover $U_s^*$ is

\begin{gather}
    C = f_s + \sum_{u \in U_s^*}d_{us}    
\end{gather}

We will need to compare $C$ with the cost of our greedy algorithm which is $\sum_{u \in U_s^*}c_u$

\hfill

\textbf{Lemma:}

\begin{gather}
    \sum_{u \in U_s^*}c_u \leq \rho(d)(f_s + \sum_{u \in U_s^*}d_{us}) = \rho(d) \cdot C
\end{gather}

where $d = |U_s^*|$.

\hfill
The algorithm covers nodes $u_1, u_2...u_d$ in $U_s^*$ in order. If we consider when the algorithm covers the $i$th node, there are two cases:

\begin{itemize}
    \item Case 1: $s \notin T$
        \subitem This implies that the cost $c_u$ is at most the cost of selecting site $s$ with set $U_s^* \cap R$ which is $c_{u_i} \leq \frac{C}{d-i+1}$
    \item Case 2: $s \in T$
        \subitem This implies that $c_{u_i} \leq d_{us}$
\end{itemize}

\hfill

If we assume that Case 1 applies for the first $k$ nodes, and after that Case 2 applies, then we can sum all the costs in $U_s^*$

\begin{gather}
    \sum_{u \in U_s^*} c_u \leq \frac{C}{d} + \frac{C}{d-1} + ... + \frac{C}{d-k+1} + \sum_{i > d}d_{u_i}, s
\end{gather}

If $d=k$ then the upper bound on the cost is in fact $\rho(d) \cdot C$. If $k < d$ then the costs $\sum_{u \in U_s^*}d_{us}$ is bounded by $C$ so it is also $\rho(d) \cdot C$.

Finally, if we let $T^*$ and $U_s^*$ be the optimal solution, the total cost is

\begin{gather}
    \sum_{s \in T^*} (f_s + \sum_{u \in U_s^*}) = \sum_{s \in T^*} \cdot C
\end{gather}

The lemma bounds each term of the cost by $\rho(d)$ proving that this is a $\rho(n)$-approximate algorithm.

\hfill

\textbf{Problem 3c.} Using the lemma to bound each term of (5) to get the optimum, we arrive at 

\begin{gather}
    OPT -  \sum_{s \in T^*} (f_s + \sum_{u \in U_s^*}) \leq \sum_{s \in T^*} \rho(n) \sum_{u \in U_s^*} c_u - \rho(n) \sum_{u \in U} c_u
\end{gather}

which would return a solution within a factor of $O(log(max_s |U_s^*|))$

\newpage
\bibliography{citation} 
\bibliographystyle{ieeetr}

\end{document} 
